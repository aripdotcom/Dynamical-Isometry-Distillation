{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d338c6d9132c>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d338c6d9132c>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    from scripts/utils import global_grad_norm_\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from torch.distributions.categorical import Categorical\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#from model import CnnActorCriticNetwork, RNDModel\n",
    "from utils import global_grad_norm_\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamical Isomentry Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_sample(obs_batch):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    sample = np.random.normal(size=obs_batch.shape)\n",
    "    sample = torch.from_numpy(sample).float().cuda()# use .to(self.device) soon \n",
    "    return sample\n",
    "\n",
    "def noise_sample_step(obs_batch, epsilon=1):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    step = np.random.normal(size=obs_batch.shape)\n",
    "    step = (step / np.linalg.norm(step)) * epsilon\n",
    "    z_obs_batch = obs_batch + step\n",
    "    z_obs_batch = torch.from_numpy(z_obs_batch).float().cuda()# use .to(self.device) soon \n",
    "    return z_obs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        init.orthogonal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnn =  nn.Sequential(nn.Linear(784, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnn.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "w = lnn[0].weight.detach().cpu().numpy()\n",
    "u,s,v = scipy.linalg.svd(w)\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plan \n",
    "#### Train model on 10 samples from class 0 - Done\n",
    "#### Create Model with separated predictors - Done\n",
    "#### Train/Test Model with separated predictors - Done\n",
    "#### Debug Model with separated predictors - In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-3cc9858d024e>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-3cc9858d024e>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    for p in self.modules():\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class AEModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(AEModel, self).__init__()\n",
    "        \n",
    "        self.activated_predictor = None\n",
    "        \n",
    "        #self.target =  nn.Sequential(nn.Linear(784, 784))\n",
    "        \n",
    "        self.predictors = {}\n",
    "        for c in range(n_classes):\n",
    "            self.predictors['predictor_'+str(c)] = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 28 * 28),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Linear(128, 64),\n",
    "            #nn.ReLU(True), \n",
    "            #nn.Linear(64, 12), \n",
    "            #nn.ReLU(True), \n",
    "            #nn.Linear(12, 3),\n",
    "            #nn.Linear(3, 12),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Linear(12, 64),\n",
    "            #nn.ReLU(True),\n",
    "            #nn.Linear(64, 128),\n",
    "            #nn.ReLU(True), \n",
    "            #nn.Linear(128, 28 * 28))\n",
    "            #nn.Tanh())\n",
    "            \n",
    "        \n",
    "        for p in self.modules():\n",
    "        #    if isinstance(p, nn.Conv2d):\n",
    "        #        init.orthogonal_(p.weight, np.sqrt(2))\n",
    "        #        p.bias.data.zero_()\n",
    "\n",
    "            if isinstance(p, nn.Linear):\n",
    "                #init.orthogonal_(p.weight, np.sqrt(2))\n",
    "                init.orthogonal_(p.weight)\n",
    "                #init.orthogonal_(p.bias)\n",
    "                #p.bias.data.zero_()\n",
    "\n",
    "        for predictor in self.predictors:\n",
    "            for param in self.predictors[predictor].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "                \n",
    "    def cuda_predictors(self):\n",
    "        for predictor in self.predictors:\n",
    "            self.predictors[predictor].cuda()\n",
    "                \n",
    "                \n",
    "    def activate_predictor(self, class_):\n",
    "        self.activated_predictor = self.predictors['predictor_'+str(class_)]\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = True\n",
    "                \n",
    "    def deactivate_predictor(self):\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def predict(self, next_obs):\n",
    "        predict_features = []\n",
    "        #target_feature = self.target(next_obs)\n",
    "        for predictor in self.predictors:\n",
    "            predict_features.append(self.predictors[predictor](next_obs))\n",
    "        return predict_features\n",
    "            \n",
    "            \n",
    "    def forward(self, next_obs):\n",
    "        #target_feature = self.target(next_obs)\n",
    "        predict_feature = self.activated_predictor(next_obs)\n",
    "\n",
    "        return predict_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEModel()\n"
     ]
    }
   ],
   "source": [
    "rnd = AEModel(10)\n",
    "rnd.to(device)\n",
    "rnd.cuda_predictors()\n",
    "print(rnd)\n",
    "\n",
    "params =[]\n",
    "for _, predictor in rnd.predictors.items():\n",
    "    params += list(predictor.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params,lr=0.001)\n",
    "forward_mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "update_proportion = 0.25\n",
    "\n",
    "\n",
    "#Batch size must be 1!\n",
    "def train(epoch, rnd, train_loader, shots_num):\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        data = data.view(data.shape[0],-1 )\n",
    "        rnd.activate_predictor(class_=y.cpu().numpy()[0])\n",
    "\n",
    "        predict_next_state_feature  = rnd(Variable(data.to(device)))\n",
    "        forward_loss = forward_mse(predict_next_state_feature, data.to(device).detach()).mean(-1)\n",
    "        forward_loss = forward_loss.sum()/len(forward_loss)\n",
    "\n",
    "        #Some unknown rnd regularization!\n",
    "        #mask = torch.rand(len(forward_loss)).to(device)\n",
    "        #mask = (mask < update_proportion).type(torch.FloatTensor).to(device)\n",
    "        #forward_loss = (forward_loss * mask).sum() / torch.max(mask.sum(), torch.Tensor([1]).to(device))\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('Now using predictor number ', y.cpu().numpy()[0])\n",
    "        #print('params before update for predictor 0:', params[0])\n",
    "        #print('params before update for predictor 1:', params[4])\n",
    "        \n",
    "        optimizer = optim.Adam(list(rnd.activated_predictor.parameters()),lr=0.001)\n",
    "        optimizer.zero_grad()\n",
    "        loss = forward_loss\n",
    "        loss.backward()\n",
    "        global_grad_norm_(list(rnd.activated_predictor.parameters()))\n",
    "        optimizer.step()\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('params after update for predictor 0:', params[0])\n",
    "        #print('params after update for predictor 1:', params[4])\n",
    "\n",
    "        #rnd.deactivate_predictor()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), shots_num,\n",
    "            100. * batch_idx / shots_num, loss.item()))\n",
    "          #train_losses.append(loss.item())\n",
    "        \n",
    "        \n",
    "def test(rnd, test_loader, shots_num=1000):\n",
    "    rnd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, y)  in enumerate(test_loader): \n",
    "            data = data.view(data.shape[0],-1 )\n",
    "            predict_next_state_feature = rnd.predict(Variable(data.to(device)))\n",
    "            for predict in predict_next_state_feature:\n",
    "                mses.append((data.to(device) - predict).pow(2).sum(1) / 2)\n",
    "            min_mse = np.argmin(mses)\n",
    "            #print('min_mse',min_mse)\n",
    "            #print('y',y.cpu().numpy()[0])\n",
    "            if min_mse==y.cpu().numpy()[0]:\n",
    "                correct+=1\n",
    "            mses = []\n",
    "        print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, batch_idx+1, 100. * correct / (batch_idx+1)))\n",
    "        #len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    #return(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 200\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    few_shot_dataset.append(data)\n",
    "    few_shot_dataset_y.append(target)\n",
    "    if len(few_shot_dataset)>num_of_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_shots = 11\n",
    "break_treshold = num_of_shots*20\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "few_shot_dataset_y_np = list(range(0,10))\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    num_of_samples = [x for x in Counter(few_shot_dataset_y_np).values()]\n",
    "    pos_of_samples = [x for x in Counter(few_shot_dataset_y_np).keys()]\n",
    "    if num_of_samples[pos_of_samples.index(target.cpu().numpy()[0])]<num_of_shots:\n",
    "        few_shot_dataset.append(data)\n",
    "        few_shot_dataset_y.append(target)\n",
    "        few_shot_dataset_y_np.append(target.cpu().numpy()[0])\n",
    "    if batch_idx>break_treshold:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 817/10000 (8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/100 (0%)]\tLoss: 1.169958\n",
      "Accuracy: 6528/10000 (65%)\n",
      "\n",
      "Train Epoch: 2 [0/100 (0%)]\tLoss: 0.922739\n",
      "Accuracy: 6882/10000 (69%)\n",
      "\n",
      "Train Epoch: 3 [0/100 (0%)]\tLoss: 0.747401\n",
      "Accuracy: 7003/10000 (70%)\n",
      "\n",
      "Train Epoch: 4 [0/100 (0%)]\tLoss: 0.594257\n",
      "Accuracy: 7123/10000 (71%)\n",
      "\n",
      "Train Epoch: 5 [0/100 (0%)]\tLoss: 0.486534\n",
      "Accuracy: 7226/10000 (72%)\n",
      "\n",
      "Train Epoch: 6 [0/100 (0%)]\tLoss: 0.451475\n",
      "Accuracy: 7315/10000 (73%)\n",
      "\n",
      "Train Epoch: 7 [0/100 (0%)]\tLoss: 0.419226\n",
      "Accuracy: 7257/10000 (73%)\n",
      "\n",
      "Train Epoch: 8 [0/100 (0%)]\tLoss: 0.386739\n",
      "Accuracy: 7366/10000 (74%)\n",
      "\n",
      "Train Epoch: 9 [0/100 (0%)]\tLoss: 0.351120\n",
      "Accuracy: 7334/10000 (73%)\n",
      "\n",
      "Train Epoch: 10 [0/100 (0%)]\tLoss: 0.325390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ab0748430f6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfew_shot_dataset_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if epoch % 10==0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-416477ca13ae>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(rnd, test_loader, shots_num)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mpredict_next_state_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_next_state_feature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mmin_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m#print('min_mse',min_mse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 500 + 1):\n",
    "    train(epoch, rnd, zip(few_shot_dataset, few_shot_dataset_y), len(few_shot_dataset))\n",
    "    #if epoch % 10==0:\n",
    "    test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
