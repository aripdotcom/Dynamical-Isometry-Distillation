{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from torch.distributions.categorical import Categorical\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#from model import CnnActorCriticNetwork, RNDModel\n",
    "from utils import global_grad_norm_\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamical Isomentry Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_sample(obs_batch):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    sample = np.random.normal(size=obs_batch.shape)\n",
    "    sample = torch.from_numpy(sample).float().cuda()# use .to(self.device) soon \n",
    "    return sample\n",
    "\n",
    "def noise_sample_step(obs_batch, epsilon=1):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    step = np.random.normal(size=obs_batch.shape)\n",
    "    step = (step / np.linalg.norm(step)) * epsilon\n",
    "    z_obs_batch = obs_batch + step\n",
    "    z_obs_batch = torch.from_numpy(z_obs_batch).float().cuda()# use .to(self.device) soon \n",
    "    return z_obs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(9, 0))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.random.randint(0,10),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(1).random_(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        init.orthogonal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnn =  nn.Sequential(nn.Linear(784, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnn.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999\n"
     ]
    }
   ],
   "source": [
    "w = lnn[0].weight.detach().cpu().numpy()\n",
    "u,s,v = scipy.linalg.svd(w)\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plan \n",
    "#### Train model on 10 samples from class 0 - Done\n",
    "#### Create Model with separated predictors - Done\n",
    "#### Train/Test Model with separated predictors - Done\n",
    "#### Debug Model with separated predictors - In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(RNDModel, self).__init__()\n",
    "        \n",
    "        self.activated_predictor = None\n",
    "        \n",
    "        self.target =  nn.Sequential(nn.Linear(784, 512))\n",
    "        \n",
    "        self.predictors = {}\n",
    "        for c in range(n_classes):\n",
    "            self.predictors['predictor_'+str(c)] = nn.Sequential(\n",
    "                nn.Linear(784, 512),\n",
    "               # nn.ReLu(),\n",
    "                #nn.Linear(512, 512),\n",
    "            )\n",
    "        \n",
    "        for p in self.modules():\n",
    "            if isinstance(p, nn.Conv2d):\n",
    "                init.orthogonal_(p.weight, np.sqrt(2))\n",
    "                p.bias.data.zero_()\n",
    "\n",
    "            if isinstance(p, nn.Linear):\n",
    "                #init.orthogonal_(p.weight, np.sqrt(2))\n",
    "                init.orthogonal_(p.weight)\n",
    "                #init.orthogonal_(p.bias)\n",
    "                #p.bias.data.zero_()\n",
    "\n",
    "        for param in self.target.parameters():\n",
    "            param.requires_grad = False\n",
    "        for predictor in self.predictors:\n",
    "            for param in self.predictors[predictor].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "                \n",
    "    def cuda_predictors(self):\n",
    "        for predictor in self.predictors:\n",
    "            self.predictors[predictor].cuda()\n",
    "                \n",
    "                \n",
    "    def activate_predictor(self, class_):\n",
    "        self.activated_predictor = self.predictors['predictor_'+str(class_)]\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = True\n",
    "                \n",
    "    def deactivate_predictor(self):\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def predict(self, next_obs):\n",
    "        predict_features = []\n",
    "        target_feature = self.target(next_obs)\n",
    "        for predictor in self.predictors:\n",
    "            predict_features.append(self.predictors[predictor](next_obs))\n",
    "        return predict_features, target_feature\n",
    "            \n",
    "            \n",
    "    def forward(self, next_obs):\n",
    "        target_feature = self.target(next_obs)\n",
    "        predict_feature = self.activated_predictor(next_obs)\n",
    "\n",
    "        return predict_feature, target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNDModel(\n",
      "  (target): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnd = RNDModel(10)\n",
    "rnd.to(device)\n",
    "rnd.cuda_predictors()\n",
    "print(rnd)\n",
    "\n",
    "params =[]\n",
    "for _, predictor in rnd.predictors.items():\n",
    "    params += list(predictor.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params,lr=0.001)\n",
    "forward_mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "update_proportion = 0.25\n",
    "\n",
    "\n",
    "#Batch size must be 1!\n",
    "def train(epoch, rnd, train_loader, shots_num):\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        data = data.view(data.shape[0],-1 )\n",
    "        rnd.activate_predictor(class_=y.cpu().numpy()[0])\n",
    "\n",
    "        predict_next_state_feature, target_next_state_feature = rnd(Variable(data.to(device)))\n",
    "        forward_loss = forward_mse(predict_next_state_feature, target_next_state_feature.detach()).mean(-1)\n",
    "        forward_loss = forward_loss.sum()/len(forward_loss)\n",
    "\n",
    "        #Some unknown rnd regularization!\n",
    "        #mask = torch.rand(len(forward_loss)).to(device)\n",
    "        #mask = (mask < update_proportion).type(torch.FloatTensor).to(device)\n",
    "        #forward_loss = (forward_loss * mask).sum() / torch.max(mask.sum(), torch.Tensor([1]).to(device))\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('Now using predictor number ', y.cpu().numpy()[0])\n",
    "        #print('params before update for predictor 0:', params[0])\n",
    "        #print('params before update for predictor 1:', params[4])\n",
    "        \n",
    "        optimizer = optim.Adam(list(rnd.activated_predictor.parameters()),lr=0.001)\n",
    "        optimizer.zero_grad()\n",
    "        loss = forward_loss\n",
    "        loss.backward()\n",
    "        global_grad_norm_(list(rnd.activated_predictor.parameters()))\n",
    "        optimizer.step()\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('params after update for predictor 0:', params[0])\n",
    "        #print('params after update for predictor 1:', params[4])\n",
    "\n",
    "        #rnd.deactivate_predictor()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), shots_num,\n",
    "            100. * batch_idx / shots_num, loss.item()))\n",
    "          #train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "def pretrain(batch_idx, rnd, data, y):\n",
    "    data = data.view(data.shape[0],-1 )\n",
    "    rnd.activate_predictor(class_=y.cpu().numpy()[0])\n",
    "\n",
    "    predict_next_state_feature, target_next_state_feature = rnd(Variable(data.to(device)))\n",
    "    forward_loss = forward_mse(predict_next_state_feature, target_next_state_feature.detach()).mean(-1)\n",
    "    forward_loss = forward_loss.sum()/len(forward_loss)\n",
    "\n",
    "    optimizer = optim.Adam(list(rnd.activated_predictor.parameters()),lr=0.001)\n",
    "    optimizer.zero_grad()\n",
    "    loss = forward_loss\n",
    "    loss.backward()\n",
    "    global_grad_norm_(list(rnd.activated_predictor.parameters()))\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 1000 == 0:\n",
    "        print('Loss: {:.6f}'.format(loss.item()))\n",
    "        \n",
    "        \n",
    "def test(rnd, test_loader, shots_num=1000):\n",
    "    rnd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, y)  in enumerate(test_loader): \n",
    "            data = data.view(data.shape[0],-1 )\n",
    "            predict_next_state_feature, target_next_state_feature = rnd.predict(Variable(data.to(device)))\n",
    "            for predict in predict_next_state_feature:\n",
    "                mses.append((target_next_state_feature - predict).pow(2).sum(1) / 2)\n",
    "            min_mse = np.argmin(mses)\n",
    "            #print('min_mse',min_mse)\n",
    "            #print('y',y.cpu().numpy()[0])\n",
    "            if min_mse==y.cpu().numpy()[0]:\n",
    "                correct+=1\n",
    "            mses = []\n",
    "        print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, batch_idx+1, 100. * correct / (batch_idx+1)))\n",
    "        #len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    #return(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.213436\n",
      "Loss: 1.278655\n",
      "Loss: 1.123878\n",
      "Loss: 1.080909\n",
      "Loss: 0.991388\n",
      "Loss: 1.086716\n",
      "Loss: 0.769583\n",
      "Loss: 0.946670\n",
      "Loss: 0.915132\n",
      "Loss: 0.743425\n",
      "Loss: 0.844830\n",
      "Loss: 0.670870\n",
      "Loss: 0.781253\n",
      "Loss: 0.684995\n",
      "Loss: 0.689395\n",
      "Loss: 0.631037\n",
      "Loss: 0.578234\n",
      "Loss: 0.595365\n",
      "Loss: 0.597020\n",
      "Loss: 0.533122\n",
      "Loss: 0.545753\n",
      "Loss: 0.501525\n",
      "Loss: 0.532914\n",
      "Loss: 0.531696\n",
      "Loss: 0.447315\n",
      "Loss: 0.535963\n",
      "Loss: 0.532086\n",
      "Loss: 0.430336\n",
      "Loss: 0.493182\n",
      "Loss: 0.481700\n",
      "Loss: 0.369355\n",
      "Loss: 0.344260\n",
      "Loss: 0.420057\n",
      "Loss: 0.414868\n",
      "Loss: 0.445324\n",
      "Loss: 0.463982\n",
      "Loss: 0.364953\n",
      "Loss: 0.405648\n",
      "Loss: 0.436920\n",
      "Loss: 0.384271\n",
      "Loss: 0.433264\n",
      "Loss: 0.343799\n",
      "Loss: 0.416409\n",
      "Loss: 0.355474\n",
      "Loss: 0.363487\n",
      "Loss: 0.371014\n",
      "Loss: 0.391464\n",
      "Loss: 0.350464\n",
      "Loss: 0.367048\n",
      "Loss: 0.406647\n",
      "Loss: 0.369788\n",
      "Loss: 0.363228\n",
      "Loss: 0.407877\n",
      "Loss: 0.381963\n",
      "Loss: 0.393192\n",
      "Loss: 0.385000\n",
      "Loss: 0.391670\n",
      "Loss: 0.356310\n",
      "Loss: 0.394854\n",
      "Loss: 0.333692\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    y = torch.LongTensor(1).random_(0, 10)\n",
    "    data = noise_sample(data)\n",
    "    pretrain(batch_idx, rnd, data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 200\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    few_shot_dataset.append(data)\n",
    "    few_shot_dataset_y.append(target)\n",
    "    if len(few_shot_dataset)>num_of_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_shots = 6\n",
    "break_trashold = num_of_shots*15\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "few_shot_dataset_y_np = list(range(0,10))\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    num_of_samples = [x for x in Counter(few_shot_dataset_y_np).values()]\n",
    "    pos_of_samples = [x for x in Counter(few_shot_dataset_y_np).keys()]\n",
    "    if num_of_samples[pos_of_samples.index(target.cpu().numpy()[0])]<num_of_shots:\n",
    "        few_shot_dataset.append(data)\n",
    "        few_shot_dataset_y.append(target)\n",
    "        few_shot_dataset_y_np.append(target.cpu().numpy()[0])\n",
    "    if batch_idx>break_trashold:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1250/10000 (12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50 (0%)]\tLoss: 1.620229\n",
      "Accuracy: 6510/10000 (65%)\n",
      "\n",
      "Train Epoch: 2 [0/50 (0%)]\tLoss: 0.756882\n",
      "Accuracy: 6707/10000 (67%)\n",
      "\n",
      "Train Epoch: 3 [0/50 (0%)]\tLoss: 0.413574\n",
      "Accuracy: 6799/10000 (68%)\n",
      "\n",
      "Train Epoch: 4 [0/50 (0%)]\tLoss: 0.254821\n",
      "Accuracy: 6848/10000 (68%)\n",
      "\n",
      "Train Epoch: 5 [0/50 (0%)]\tLoss: 0.194577\n",
      "Accuracy: 6920/10000 (69%)\n",
      "\n",
      "Train Epoch: 6 [0/50 (0%)]\tLoss: 0.143619\n",
      "Accuracy: 6913/10000 (69%)\n",
      "\n",
      "Train Epoch: 7 [0/50 (0%)]\tLoss: 0.142241\n",
      "Accuracy: 6970/10000 (70%)\n",
      "\n",
      "Train Epoch: 8 [0/50 (0%)]\tLoss: 0.132231\n",
      "Accuracy: 6886/10000 (69%)\n",
      "\n",
      "Train Epoch: 9 [0/50 (0%)]\tLoss: 0.120312\n",
      "Accuracy: 6831/10000 (68%)\n",
      "\n",
      "Train Epoch: 10 [0/50 (0%)]\tLoss: 0.122781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-f6e11a96da5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfew_shot_dataset_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-037ca0dfc51c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(rnd, test_loader, shots_num)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mpredict_next_state_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_next_state_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_next_state_feature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_next_state_feature\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-13ba3943ae53>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, next_obs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mtarget_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mpredict_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aasadulaev/soft/conda2/envs/jpoenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aasadulaev/soft/conda2/envs/jpoenv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aasadulaev/soft/conda2/envs/jpoenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aasadulaev/soft/conda2/envs/jpoenv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aasadulaev/soft/conda2/envs/jpoenv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 500 + 1):\n",
    "    train(epoch, rnd, zip(few_shot_dataset, few_shot_dataset_y), len(few_shot_dataset))\n",
    "    test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
