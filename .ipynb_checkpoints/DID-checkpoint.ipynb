{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from torch.distributions.categorical import Categorical\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#from model import CnnActorCriticNetwork, RNDModel\n",
    "from utils import global_grad_norm_\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamical Isomentry Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_sample(obs_batch):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    sample = np.random.normal(size=obs_batch.shape)\n",
    "    sample = torch.from_numpy(sample).float().cuda()# use .to(self.device) soon \n",
    "    return sample\n",
    "\n",
    "def noise_sample_step(obs_batch, epsilon=1):\n",
    "    obs_batch = obs_batch.cpu().detach().numpy()\n",
    "    step = np.random.normal(size=obs_batch.shape)\n",
    "    step = (step / np.linalg.norm(step)) * epsilon\n",
    "    z_obs_batch = obs_batch + step\n",
    "    z_obs_batch = torch.from_numpy(z_obs_batch).float().cuda()# use .to(self.device) soon \n",
    "    return z_obs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        init.orthogonal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnn =  nn.Sequential(nn.Linear(784, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnn.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "w = lnn[0].weight.detach().cpu().numpy()\n",
    "u,s,v = scipy.linalg.svd(w)\n",
    "print(np.mean(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plan \n",
    "#### Train model on 10 samples from class 0 - Done\n",
    "#### Create Model with separated predictors - Done\n",
    "#### Train/Test Model with separated predictors - Done\n",
    "#### Debug Model with separated predictors - In progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(RNDModel, self).__init__()\n",
    "        \n",
    "        self.activated_predictor = None\n",
    "        \n",
    "        self.target =  nn.Sequential(nn.Linear(784, 784))\n",
    "        \n",
    "        self.predictors = {}\n",
    "        for c in range(n_classes):\n",
    "            self.predictors['predictor_'+str(c)] = nn.Sequential(\n",
    "                nn.Linear(784, 784),\n",
    "                #nn.ReLU(),\n",
    "                #nn.Linear(512, 512),\n",
    "            )\n",
    "        \n",
    "        for p in self.modules():\n",
    "            if isinstance(p, nn.Conv2d):\n",
    "                init.orthogonal_(p.weight, np.sqrt(2))\n",
    "                p.bias.data.zero_()\n",
    "\n",
    "            if isinstance(p, nn.Linear):\n",
    "                #init.orthogonal_(p.weight, np.sqrt(2))\n",
    "                init.orthogonal_(p.weight)\n",
    "                #init.orthogonal_(p.bias)\n",
    "                #p.bias.data.zero_()\n",
    "\n",
    "        for param in self.target.parameters():\n",
    "            param.requires_grad = False\n",
    "        for predictor in self.predictors:\n",
    "            for param in self.predictors[predictor].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "                \n",
    "    def cuda_predictors(self):\n",
    "        for predictor in self.predictors:\n",
    "            self.predictors[predictor].cuda()\n",
    "                \n",
    "                \n",
    "    def activate_predictor(self, class_):\n",
    "        self.activated_predictor = self.predictors['predictor_'+str(class_)]\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = True\n",
    "                \n",
    "    def deactivate_predictor(self):\n",
    "        for param in self.activated_predictor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def predict(self, next_obs):\n",
    "        predict_features = []\n",
    "        target_feature = self.target(next_obs)\n",
    "        for predictor in self.predictors:\n",
    "            predict_features.append(self.predictors[predictor](next_obs))\n",
    "        return predict_features, target_feature\n",
    "            \n",
    "            \n",
    "    def forward(self, next_obs):\n",
    "        target_feature = self.target(next_obs)\n",
    "        predict_feature = self.activated_predictor(next_obs)\n",
    "\n",
    "        return predict_feature, target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNDModel(\n",
      "  (target): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnd = RNDModel(10)\n",
    "rnd.to(device)\n",
    "rnd.cuda_predictors()\n",
    "print(rnd)\n",
    "\n",
    "params =[]\n",
    "for _, predictor in rnd.predictors.items():\n",
    "    params += list(predictor.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params,lr=0.001)\n",
    "forward_mse = nn.MSELoss(reduction='none')\n",
    "\n",
    "update_proportion = 0.25\n",
    "\n",
    "\n",
    "#Batch size must be 1!\n",
    "def train(epoch, rnd, train_loader, shots_num):\n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        data = data.view(data.shape[0],-1 )\n",
    "        rnd.activate_predictor(class_=y.cpu().numpy()[0])\n",
    "\n",
    "        predict_next_state_feature, target_next_state_feature = rnd(Variable(data.to(device)))\n",
    "        forward_loss = forward_mse(predict_next_state_feature, target_next_state_feature.detach()).mean(-1)\n",
    "        forward_loss = forward_loss.sum()/len(forward_loss)\n",
    "\n",
    "        #Some unknown rnd regularization!\n",
    "        #mask = torch.rand(len(forward_loss)).to(device)\n",
    "        #mask = (mask < update_proportion).type(torch.FloatTensor).to(device)\n",
    "        #forward_loss = (forward_loss * mask).sum() / torch.max(mask.sum(), torch.Tensor([1]).to(device))\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('Now using predictor number ', y.cpu().numpy()[0])\n",
    "        #print('params before update for predictor 0:', params[0])\n",
    "        #print('params before update for predictor 1:', params[4])\n",
    "        \n",
    "        optimizer = optim.Adam(list(rnd.activated_predictor.parameters()),lr=0.001)\n",
    "        optimizer.zero_grad()\n",
    "        loss = forward_loss\n",
    "        loss.backward()\n",
    "        global_grad_norm_(list(rnd.activated_predictor.parameters()))\n",
    "        optimizer.step()\n",
    "        \n",
    "        #params =[]\n",
    "        #for _, predictor in rnd.predictors.items():\n",
    "        #    params += list(predictor.parameters())\n",
    "        #print('params after update for predictor 0:', params[0])\n",
    "        #print('params after update for predictor 1:', params[4])\n",
    "\n",
    "        #rnd.deactivate_predictor()\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), shots_num,\n",
    "            100. * batch_idx / shots_num, loss.item()))\n",
    "          #train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "def pretrain(batch_idx, rnd, data, y):\n",
    "    data = data.view(data.shape[0],-1 )\n",
    "    rnd.activate_predictor(class_=y.cpu().numpy()[0])\n",
    "\n",
    "    predict_next_state_feature, target_next_state_feature = rnd(Variable(data.to(device)))\n",
    "    forward_loss = forward_mse(predict_next_state_feature, target_next_state_feature.detach()).mean(-1)\n",
    "    forward_loss = forward_loss.sum()/len(forward_loss)\n",
    "\n",
    "    optimizer = optim.Adam(list(rnd.activated_predictor.parameters()),lr=0.001)\n",
    "    optimizer.zero_grad()\n",
    "    loss = forward_loss\n",
    "    loss.backward()\n",
    "    global_grad_norm_(list(rnd.activated_predictor.parameters()))\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 1000 == 0:\n",
    "        print('Loss: {:.6f}'.format(loss.item()))\n",
    "        \n",
    "        \n",
    "def test(rnd, test_loader, shots_num=1000):\n",
    "    rnd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    mses = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, y)  in enumerate(test_loader): \n",
    "            data = data.view(data.shape[0],-1 )\n",
    "            predict_next_state_feature, target_next_state_feature = rnd.predict(Variable(data.to(device)))\n",
    "            for predict in predict_next_state_feature:\n",
    "                mses.append((target_next_state_feature - predict).pow(2).sum(1) / 2)\n",
    "            min_mse = np.argmin(mses)\n",
    "            #print('min_mse',min_mse)\n",
    "            #print('y',y.cpu().numpy()[0])\n",
    "            if min_mse==y.cpu().numpy()[0]:\n",
    "                correct+=1\n",
    "            mses = []\n",
    "        print('Accuracy: {}/{} ({:.0f}%)\\n'.format(correct, batch_idx+1, 100. * correct / (batch_idx+1)))\n",
    "        #len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    #return(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.213436\n",
      "Loss: 1.278655\n",
      "Loss: 1.123878\n",
      "Loss: 1.080909\n",
      "Loss: 0.991388\n",
      "Loss: 1.086716\n",
      "Loss: 0.769583\n",
      "Loss: 0.946670\n",
      "Loss: 0.915132\n",
      "Loss: 0.743425\n",
      "Loss: 0.844830\n",
      "Loss: 0.670870\n",
      "Loss: 0.781253\n",
      "Loss: 0.684995\n",
      "Loss: 0.689395\n",
      "Loss: 0.631037\n",
      "Loss: 0.578234\n",
      "Loss: 0.595365\n",
      "Loss: 0.597020\n",
      "Loss: 0.533122\n",
      "Loss: 0.545753\n",
      "Loss: 0.501525\n",
      "Loss: 0.532914\n",
      "Loss: 0.531696\n",
      "Loss: 0.447315\n",
      "Loss: 0.535963\n",
      "Loss: 0.532086\n",
      "Loss: 0.430336\n",
      "Loss: 0.493182\n",
      "Loss: 0.481700\n",
      "Loss: 0.369355\n",
      "Loss: 0.344260\n",
      "Loss: 0.420057\n",
      "Loss: 0.414868\n",
      "Loss: 0.445324\n",
      "Loss: 0.463982\n",
      "Loss: 0.364953\n",
      "Loss: 0.405648\n",
      "Loss: 0.436920\n",
      "Loss: 0.384271\n",
      "Loss: 0.433264\n",
      "Loss: 0.343799\n",
      "Loss: 0.416409\n",
      "Loss: 0.355474\n",
      "Loss: 0.363487\n",
      "Loss: 0.371014\n",
      "Loss: 0.391464\n",
      "Loss: 0.350464\n",
      "Loss: 0.367048\n",
      "Loss: 0.406647\n",
      "Loss: 0.369788\n",
      "Loss: 0.363228\n",
      "Loss: 0.407877\n",
      "Loss: 0.381963\n",
      "Loss: 0.393192\n",
      "Loss: 0.385000\n",
      "Loss: 0.391670\n",
      "Loss: 0.356310\n",
      "Loss: 0.394854\n",
      "Loss: 0.333692\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    y = torch.LongTensor(1).random_(0, 10)\n",
    "    data = noise_sample(data)\n",
    "    pretrain(batch_idx, rnd, data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 200\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    few_shot_dataset.append(data)\n",
    "    few_shot_dataset_y.append(target)\n",
    "    if len(few_shot_dataset)>num_of_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_shots = 11\n",
    "break_treshold = num_of_shots*20\n",
    "few_shot_dataset = []\n",
    "few_shot_dataset_y = []\n",
    "few_shot_dataset_y_np = list(range(0,10))\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    num_of_samples = [x for x in Counter(few_shot_dataset_y_np).values()]\n",
    "    pos_of_samples = [x for x in Counter(few_shot_dataset_y_np).keys()]\n",
    "    if num_of_samples[pos_of_samples.index(target.cpu().numpy()[0])]<num_of_shots:\n",
    "        few_shot_dataset.append(data)\n",
    "        few_shot_dataset_y.append(target)\n",
    "        few_shot_dataset_y_np.append(target.cpu().numpy()[0])\n",
    "    if batch_idx>break_treshold:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1250/10000 (12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/100 (0%)]\tLoss: 1.902604\n",
      "Accuracy: 7640/10000 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/100 (0%)]\tLoss: 0.548579\n",
      "Accuracy: 7902/10000 (79%)\n",
      "\n",
      "Train Epoch: 3 [0/100 (0%)]\tLoss: 0.368947\n",
      "Accuracy: 7945/10000 (79%)\n",
      "\n",
      "Train Epoch: 4 [0/100 (0%)]\tLoss: 0.337825\n",
      "Accuracy: 8010/10000 (80%)\n",
      "\n",
      "Train Epoch: 5 [0/100 (0%)]\tLoss: 0.305008\n",
      "Accuracy: 7941/10000 (79%)\n",
      "\n",
      "Train Epoch: 6 [0/100 (0%)]\tLoss: 0.284644\n",
      "Accuracy: 7977/10000 (80%)\n",
      "\n",
      "Train Epoch: 7 [0/100 (0%)]\tLoss: 0.253951\n",
      "Accuracy: 7998/10000 (80%)\n",
      "\n",
      "Train Epoch: 8 [0/100 (0%)]\tLoss: 0.218290\n",
      "Accuracy: 8008/10000 (80%)\n",
      "\n",
      "Train Epoch: 9 [0/100 (0%)]\tLoss: 0.211844\n",
      "Accuracy: 8027/10000 (80%)\n",
      "\n",
      "Train Epoch: 10 [0/100 (0%)]\tLoss: 0.207565\n",
      "Accuracy: 8012/10000 (80%)\n",
      "\n",
      "Train Epoch: 11 [0/100 (0%)]\tLoss: 0.206306\n",
      "Accuracy: 8032/10000 (80%)\n",
      "\n",
      "Train Epoch: 12 [0/100 (0%)]\tLoss: 0.202770\n",
      "Accuracy: 8003/10000 (80%)\n",
      "\n",
      "Train Epoch: 13 [0/100 (0%)]\tLoss: 0.187258\n",
      "Accuracy: 8001/10000 (80%)\n",
      "\n",
      "Train Epoch: 14 [0/100 (0%)]\tLoss: 0.191169\n",
      "Accuracy: 7983/10000 (80%)\n",
      "\n",
      "Train Epoch: 15 [0/100 (0%)]\tLoss: 0.197048\n",
      "Accuracy: 8030/10000 (80%)\n",
      "\n",
      "Train Epoch: 16 [0/100 (0%)]\tLoss: 0.195692\n",
      "Accuracy: 7976/10000 (80%)\n",
      "\n",
      "Train Epoch: 17 [0/100 (0%)]\tLoss: 0.212711\n",
      "Accuracy: 8053/10000 (81%)\n",
      "\n",
      "Train Epoch: 18 [0/100 (0%)]\tLoss: 0.213736\n",
      "Accuracy: 8009/10000 (80%)\n",
      "\n",
      "Train Epoch: 19 [0/100 (0%)]\tLoss: 0.200348\n",
      "Accuracy: 8028/10000 (80%)\n",
      "\n",
      "Train Epoch: 20 [0/100 (0%)]\tLoss: 0.208352\n",
      "Accuracy: 8049/10000 (80%)\n",
      "\n",
      "Train Epoch: 21 [0/100 (0%)]\tLoss: 0.218336\n",
      "Accuracy: 8040/10000 (80%)\n",
      "\n",
      "Train Epoch: 22 [0/100 (0%)]\tLoss: 0.197968\n",
      "Accuracy: 7980/10000 (80%)\n",
      "\n",
      "Train Epoch: 23 [0/100 (0%)]\tLoss: 0.205417\n",
      "Accuracy: 8034/10000 (80%)\n",
      "\n",
      "Train Epoch: 24 [0/100 (0%)]\tLoss: 0.214088\n",
      "Accuracy: 8015/10000 (80%)\n",
      "\n",
      "Train Epoch: 25 [0/100 (0%)]\tLoss: 0.224149\n",
      "Accuracy: 8077/10000 (81%)\n",
      "\n",
      "Train Epoch: 26 [0/100 (0%)]\tLoss: 0.225218\n",
      "Accuracy: 8011/10000 (80%)\n",
      "\n",
      "Train Epoch: 27 [0/100 (0%)]\tLoss: 0.222952\n",
      "Accuracy: 8032/10000 (80%)\n",
      "\n",
      "Train Epoch: 28 [0/100 (0%)]\tLoss: 0.231843\n",
      "Accuracy: 8031/10000 (80%)\n",
      "\n",
      "Train Epoch: 29 [0/100 (0%)]\tLoss: 0.212302\n",
      "Accuracy: 8051/10000 (81%)\n",
      "\n",
      "Train Epoch: 30 [0/100 (0%)]\tLoss: 0.224650\n",
      "Accuracy: 7999/10000 (80%)\n",
      "\n",
      "Train Epoch: 31 [0/100 (0%)]\tLoss: 0.223582\n",
      "Accuracy: 8047/10000 (80%)\n",
      "\n",
      "Train Epoch: 32 [0/100 (0%)]\tLoss: 0.229627\n",
      "Accuracy: 8015/10000 (80%)\n",
      "\n",
      "Train Epoch: 33 [0/100 (0%)]\tLoss: 0.228035\n",
      "Accuracy: 8059/10000 (81%)\n",
      "\n",
      "Train Epoch: 34 [0/100 (0%)]\tLoss: 0.226236\n",
      "Accuracy: 8023/10000 (80%)\n",
      "\n",
      "Train Epoch: 35 [0/100 (0%)]\tLoss: 0.214904\n",
      "Accuracy: 8040/10000 (80%)\n",
      "\n",
      "Train Epoch: 36 [0/100 (0%)]\tLoss: 0.227986\n",
      "Accuracy: 8028/10000 (80%)\n",
      "\n",
      "Train Epoch: 37 [0/100 (0%)]\tLoss: 0.222937\n",
      "Accuracy: 8080/10000 (81%)\n",
      "\n",
      "Train Epoch: 38 [0/100 (0%)]\tLoss: 0.235325\n",
      "Accuracy: 8033/10000 (80%)\n",
      "\n",
      "Train Epoch: 39 [0/100 (0%)]\tLoss: 0.219857\n",
      "Accuracy: 8027/10000 (80%)\n",
      "\n",
      "Train Epoch: 40 [0/100 (0%)]\tLoss: 0.230366\n",
      "Accuracy: 8020/10000 (80%)\n",
      "\n",
      "Train Epoch: 41 [0/100 (0%)]\tLoss: 0.230452\n",
      "Accuracy: 8050/10000 (80%)\n",
      "\n",
      "Train Epoch: 42 [0/100 (0%)]\tLoss: 0.230752\n",
      "Accuracy: 8004/10000 (80%)\n",
      "\n",
      "Train Epoch: 43 [0/100 (0%)]\tLoss: 0.222646\n",
      "Accuracy: 8021/10000 (80%)\n",
      "\n",
      "Train Epoch: 44 [0/100 (0%)]\tLoss: 0.230077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-f6e11a96da5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfew_shot_dataset_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfew_shot_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-037ca0dfc51c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(rnd, test_loader, shots_num)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mpredict_next_state_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_next_state_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredict_next_state_feature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_next_state_feature\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mmin_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m#print('min_mse',min_mse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 500 + 1):\n",
    "    train(epoch, rnd, zip(few_shot_dataset, few_shot_dataset_y), len(few_shot_dataset))\n",
    "    test(rnd, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
